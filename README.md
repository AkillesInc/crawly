# Crawly

**Commands**

1. Start crawler:
`Crawly.EngineSup.start_manager(BlogEsl)`

**Tasks**

***General***
Listen to robots.txt
Throttle
Stopspider signal
Read parameters from settings...

***URL storage***
    1. Persistant fingerprints for duplicates filtering...
    2. Migrate fingerprints to maps

***Data storage***
1. How to close fd?
2. How to make proper filenames?
3. Support -o option to pipe data filename
